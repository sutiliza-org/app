{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNoEgJAJslj/2rLzVWCJO3i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sutiliza-org/app/blob/main/io.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SDXRXjwhABHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506fefe7-d704-43f4-fa0c-1afbc62fc5d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive montado em: /content/drive\n",
            "Correlação de Pearson (Tempo Codificação (min) vs. Atividade Alfa (µV²)): 0.993, p=0.000\n",
            "Correlação de Spearman (Tempo Codificação (min) vs. Atividade Alfa (µV²)): 0.998, p=0.000\n",
            "Correlação de Pearson (Erros vs. Atividade Beta (µV²)): -0.941, p=0.000\n",
            "Correlação de Spearman (Erros vs. Atividade Beta (µV²)): -0.982, p=0.000\n",
            "                               OLS Regression Results                              \n",
            "===================================================================================\n",
            "Dep. Variable:     Tempo Codificação (min)   R-squared:                       0.996\n",
            "Model:                                 OLS   Adj. R-squared:                  0.995\n",
            "Method:                      Least Squares   F-statistic:                     1155.\n",
            "Date:                     Sun, 09 Feb 2025   Prob (F-statistic):           1.35e-36\n",
            "Time:                             07:06:04   Log-Likelihood:                -51.572\n",
            "No. Observations:                       40   AIC:                             119.1\n",
            "Df Residuals:                           32   BIC:                             132.7\n",
            "Df Model:                                7                                         \n",
            "Covariance Type:                 nonrobust                                         \n",
            "================================================================================================\n",
            "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------------\n",
            "const                           25.6274     17.851      1.436      0.161     -10.734      61.989\n",
            "Atividade Alfa (µV²)             2.9235      1.523      1.920      0.064      -0.178       6.025\n",
            "Atividade Beta (µV²)            -0.9768      0.508     -1.923      0.063      -2.012       0.058\n",
            "Atenção Sustentada (Escore)      7.8666      3.105      2.533      0.016       1.541      14.192\n",
            "Memória de Trabalho (Escore)    -4.9623      3.496     -1.420      0.165     -12.082       2.158\n",
            "Controle Inibitório (Escore)    -2.8336      1.085     -2.612      0.014      -5.043      -0.624\n",
            "Complexidade Ciclomática         1.0355      0.439      2.357      0.025       0.141       1.930\n",
            "Erros                            0.7262      0.477      1.523      0.138      -0.245       1.697\n",
            "==============================================================================\n",
            "Omnibus:                        0.296   Durbin-Watson:                   1.890\n",
            "Prob(Omnibus):                  0.863   Jarque-Bera (JB):                0.415\n",
            "Skew:                          -0.180   Prob(JB):                        0.813\n",
            "Kurtosis:                       2.656   Cond. No.                     2.75e+03\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.75e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "Sumário estatístico salvo em: /content/drive/MyDrive/sumario.txt\n",
            "Análise completa, gráficos e sumário gerados!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import io\n",
        "import requests\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statsmodels.api as sm\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- Configurações e Constantes ---\n",
        "DRIVE_MOUNT_PATH = \"/content/drive\"\n",
        "GRAPHPATH = os.path.join(DRIVE_MOUNT_PATH, \"MyDrive\", \"graficos\")  # Pasta para gráficos\n",
        "SUMMARYPATH = os.path.join(DRIVE_MOUNT_PATH, \"MyDrive\")  # Pasta raiz para o sumário\n",
        "DATASET_URL = \"https://docs.google.com/spreadsheets/d/13IWvMp6SA7GCJybJVcw92EN-NaQC4bRSWeP8Y_YPH1Y/export?format=csv\"\n",
        "DEFAULT_PALETTE = \"viridis\"\n",
        "FIGSIZE = (10, 6)\n",
        "\n",
        "# Estilo dos gráficos\n",
        "sns.set(style=\"darkgrid\")\n",
        "plt.rcParams.update({\n",
        "    'figure.facecolor': 'black',\n",
        "    'axes.facecolor': 'black',\n",
        "    'axes.edgecolor': 'white',\n",
        "    'axes.labelcolor': 'cyan',\n",
        "    'xtick.color': 'white',\n",
        "    'ytick.color': 'white',\n",
        "    'text.color': 'white',\n",
        "    'grid.color': 'gray',\n",
        "    'grid.linestyle': '--',\n",
        "    'legend.facecolor': 'black',\n",
        "    'legend.edgecolor': 'white',\n",
        "    'figure.titlesize': 18,\n",
        "    'axes.titlesize': 14,\n",
        "    'axes.labelsize': 12,\n",
        "})\n",
        "\n",
        "# --- Funções Auxiliares ---\n",
        "def save_fig(fig, filename):\n",
        "    \"\"\"Salva a figura no Drive, na pasta 'graficos'.\"\"\"\n",
        "    filepath = os.path.join(GRAPHPATH, filename)\n",
        "    os.makedirs(os.path.dirname(filepath), exist_ok=True)  # Garante que a pasta existe\n",
        "    fig.savefig(filepath, dpi=300, bbox_inches='tight')\n",
        "    plt.close(fig)  # Fecha a figura *imediatamente* após salvar\n",
        "\n",
        "def create_figure():\n",
        "    \"\"\"Cria uma figura com o tamanho padrão.\"\"\"\n",
        "    return plt.figure(figsize=FIGSIZE)  # Retorna a figura diretamente\n",
        "\n",
        "def load_data_from_url(url):\n",
        "    \"\"\"Carrega dados de uma URL CSV.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        csv_content = response.content.decode('utf-8')\n",
        "        df = pd.read_csv(io.StringIO(csv_content))\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar dados: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Função para Salvar Sumário ---\n",
        "def generate_statistical_summary(df, filename=\"sumario.txt\"):\n",
        "    \"\"\"Gera um sumário estatístico e salva em um arquivo na pasta raiz do Google Drive.\"\"\"\n",
        "    try:\n",
        "        summary = df.describe().to_string()\n",
        "        filepath = os.path.join(SUMMARYPATH, filename)\n",
        "        os.makedirs(os.path.dirname(filepath), exist_ok=True)  # Garante que a pasta existe\n",
        "        with open(filepath, 'w') as f:\n",
        "            f.write(summary)\n",
        "        print(f\"Sumário estatístico salvo em: {filepath}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao gerar sumário estatístico: {e}\")\n",
        "\n",
        "# --- Funções de Visualização (Refatoradas - Simplificadas) ---\n",
        "def generate_correlation_heatmap(df, title, filename):\n",
        "    fig = create_figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)  # Adiciona um único Axes\n",
        "    corr = df.corr()\n",
        "    sns.heatmap(corr, annot=True, cmap=DEFAULT_PALETTE, fmt=\".2f\", linewidths=.5, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    save_fig(fig, filename)\n",
        "\n",
        "def generate_scatterplot(df, x_col, y_col, title, filename, hue=None, style=None):\n",
        "    fig = create_figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    sns.scatterplot(x=x_col, y=y_col, data=df, hue=hue, style=style, palette=DEFAULT_PALETTE, alpha=0.7, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    save_fig(fig, filename)\n",
        "\n",
        "def generate_histogram(df, col, title, filename, bins=20, kde=True):\n",
        "    fig = create_figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    sns.histplot(df[col], kde=kde, bins=bins, color='skyblue', ax=ax)\n",
        "    ax.set_title(title)\n",
        "    save_fig(fig, filename)\n",
        "\n",
        "def generate_boxplot(df, x_col, y_col, title, filename, hue=None):\n",
        "    fig = create_figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    if hue:\n",
        "        sns.boxplot(x=x_col, y=y_col, data=df, hue=hue, palette=DEFAULT_PALETTE, ax=ax)\n",
        "    else:\n",
        "        sns.boxplot(x=x_col, y=y_col, data=df, palette=DEFAULT_PALETTE, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "    save_fig(fig, filename)\n",
        "\n",
        "def generate_violinplot(df, x_col, y_col, title, filename, hue=None, split=False):\n",
        "    fig = create_figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    sns.violinplot(x=x_col, y=y_col, data=df, hue=hue, split=split, palette=DEFAULT_PALETTE, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "    save_fig(fig, filename)\n",
        "\n",
        "def generate_pairplot(df, title, filename, hue=None):\n",
        "    pairplot = sns.pairplot(df, hue=hue, palette=DEFAULT_PALETTE)\n",
        "    pairplot.fig.suptitle(title, y=1.02)\n",
        "    save_fig(pairplot.fig, filename)  # Salva pairplot.fig\n",
        "\n",
        "def generate_pca_plot(df, features, title, filename, hue=None, n_components=2):\n",
        "    fig = create_figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    df_pca = df[features].dropna()\n",
        "    if df_pca.empty:\n",
        "        print(\"Sem dados para PCA.\")\n",
        "        return\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(df_pca)\n",
        "    pca = PCA(n_components=n_components)\n",
        "    principal_components = pca.fit_transform(scaled_data)\n",
        "    pca_df = pd.DataFrame(data=principal_components, columns=[f'PC{i+1}' for i in range(n_components)])\n",
        "    if hue and hue in df.columns:\n",
        "        pca_df = pca_df.set_index(df_pca.index)\n",
        "        pca_df[hue] = df[hue].loc[pca_df.index]\n",
        "    sns.scatterplot(x='PC1', y='PC2', data=pca_df, hue=hue, palette=DEFAULT_PALETTE, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    save_fig(fig, filename)\n",
        "\n",
        "# --- Função Principal (main) ---\n",
        "if __name__ == \"__main__\":\n",
        "    drive.mount(DRIVE_MOUNT_PATH, force_remount=True)\n",
        "    print(f\"Drive montado em: {DRIVE_MOUNT_PATH}\")\n",
        "\n",
        "    # Garante que as pastas existem\n",
        "    os.makedirs(GRAPHPATH, exist_ok=True)\n",
        "    os.makedirs(SUMMARYPATH, exist_ok=True)\n",
        "\n",
        "    # Carrega os dados\n",
        "    df = load_data_from_url(DATASET_URL)\n",
        "    if df is None:\n",
        "        print(\"Não foi possível carregar os dados. Encerrando.\")\n",
        "        exit()\n",
        "\n",
        "    # --- Análises e Visualizações (12+ Gráficos) ---\n",
        "    generate_correlation_heatmap(df, \"1. Heatmap de Correlação (Completo)\", \"1_heatmap_completo.png\")\n",
        "    generate_scatterplot(df, 'Tempo Codificação (min)', 'Atividade Alfa (µV²)', \"2. Tempo de Codificação vs. Atividade Alfa\", \"2_scatter_tempo_alfa.png\")\n",
        "    generate_scatterplot(df, 'Erros', 'Atividade Beta (µV²)', \"3. Erros vs. Atividade Beta\", \"3_scatter_erros_beta.png\")\n",
        "    generate_histogram(df, 'Tempo Codificação (min)', \"4. Distribuição do Tempo de Codificação\", \"4_hist_tempo.png\")\n",
        "    generate_histogram(df, 'Erros', \"5. Distribuição de Erros\", \"5_hist_erros.png\")\n",
        "\n",
        "    cluster_features = ['Tempo Codificação (min)', 'Erros', 'Complexidade Ciclomática']\n",
        "    clusters = perform_kmeans_clustering(df, cluster_features, n_clusters=3)\n",
        "    if clusters is not None:\n",
        "        df['Cluster'] = clusters\n",
        "        generate_boxplot(df, 'Cluster', 'Tempo Codificação (min)', \"6. Tempo de Codificação por Cluster\", \"6_boxplot_tempo_cluster.png\")\n",
        "\n",
        "    pca_features = ['Atenção Sustentada (Escore)', 'Memória de Trabalho (Escore)', 'Controle Inibitório (Escore)']\n",
        "    generate_pca_plot(df, pca_features, \"7. PCA Plot\", \"7_pca_plot.png\")\n",
        "    generate_scatterplot(df, 'Complexidade Ciclomática', 'Tempo Codificação (min)', \"8. Complexidade vs. Tempo (por Cluster)\", \"8_scatter_complexidade_tempo.png\", hue='Cluster')\n",
        "    generate_violinplot(df, 'Cluster', 'Atividade Alfa (µV²)', \"9. Atividade Alfa por Cluster\", \"9_violin_alfa_cluster.png\")\n",
        "    generate_boxplot(df, 'Cluster', 'Erros', \"10. Erros por Cluster\", \"10_boxplot_erros_cluster.png\")\n",
        "    generate_scatterplot(df, 'Atenção Sustentada (Escore)', 'Memória de Trabalho (Escore)', \"11. Atenção Sustentada vs. Memória de Trabalho\", \"11_scatter_atencao_memoria.png\")\n",
        "    generate_histogram(df, 'Complexidade Ciclomática', \"12. Distribuição da Complexidade Ciclomática\", \"12_hist_complexidade.png\")\n",
        "\n",
        "    pairplot_vars = ['Tempo Codificação (min)', 'Erros', 'Atividade Alfa (µV²)', 'Atividade Beta (µV²)']\n",
        "    generate_pairplot(df[pairplot_vars], \"13. Pairplot (Variáveis Selecionadas)\", \"13_pairplot.png\")\n",
        "\n",
        "    # --- Análise Estatística e Sumário ---\n",
        "    calculate_correlations(df, 'Tempo Codificação (min)', 'Atividade Alfa (µV²)')\n",
        "    calculate_correlations(df, 'Erros', 'Atividade Beta (µV²)')\n",
        "\n",
        "    regression_features = [\n",
        "        'Atividade Alfa (µV²)', 'Atividade Beta (µV²)', 'Atenção Sustentada (Escore)',\n",
        "        'Memória de Trabalho (Escore)', 'Controle Inibitório (Escore)', 'Complexidade Ciclomática',\n",
        "        'Erros'\n",
        "    ]\n",
        "    perform_linear_regression(df, regression_features, 'Tempo Codificação (min)')\n",
        "\n",
        "    generate_statistical_summary(df, \"sumario.txt\")  # Gera o sumário na pasta raiz\n",
        "\n",
        "    drive.flush_and_unmount()\n",
        "    print(\"Análise completa, gráficos e sumário gerados!\")"
      ]
    }
  ]
}